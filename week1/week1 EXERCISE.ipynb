{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "# OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "# HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "# MODEL = \"llama3.2\"\n",
    "# MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5421d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a highly skilled tutor who is tutoring a student in a subject you know very well.\\\n",
    "The student is struggling to understand a concept. You decide to explain the concept to the student \\\n",
    "in a way that is easy to understand.\"\n",
    "user_prompt = \"\"\"Please explain what this code does and why:\n",
    "user_promptyield from {book.get(\"author\") for book in books if book.get(\"author\")}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def get_answer():\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f5469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Let's break down the code snippet you provided. \n",
       "\n",
       "The code appears to be a Python generator that uses a set comprehension along with `yield from`. Here's what each part does:\n",
       "\n",
       "1. **List of books**: The code seems to be assuming that there is a list of dictionaries called `books`, where each dictionary represents a book and contains information about that book, such as the title and author. \n",
       "\n",
       "2. **Set comprehension**: `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension. This means that you are creating a set of authors from the `books` list. The expression works as follows:\n",
       "   - `for book in books`: This loops through each individual `book` in the `books` list.\n",
       "   - `book.get(\"author\")`: This retrieves the value associated with the key \"author\" from each book dictionary. The `get` method is used to safely access the value — if the key doesn't exist, it returns `None` instead of raising an error.\n",
       "   - `if book.get(\"author\")`: This condition filters out any books that do not have an author listed. If `book.get(\"author\")` returns `None` (i.e., there is no author listed), that book is skipped.\n",
       "\n",
       "3. **`yield from`**: The `yield from` statement is used in Python to yield values from a generator. What it does here is take the set of authors generated from the set comprehension and yield each author one at a time. This allows the code to be part of a generator function, enabling the iterative process of producing output without having to return everything at once.\n",
       "\n",
       "### Putting It All Together:\n",
       "So, the complete line of code creates a generator that will yield each unique author from the list of book dictionaries, but only if the author exists. The uniqueness is ensured because it’s using a set to store the authors.\n",
       "\n",
       "### Example:\n",
       "Suppose you have the following list of books:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": None},\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"}\n",
       "]\n",
       "\n",
       "\n",
       "In this case, the set comprehension will create a set with unique authors: `{\"Author A\", \"Author B\"}`. Then, `yield from` will allow you to iterate over these authors one at a time when the generator is consumed, effectively providing each author without duplication and without returning the entire set at once.\n",
       "\n",
       "I hope this explanation helps clarify what the code is doing! If you have any more questions about specific parts or concepts, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ec5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06bbcdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a highly skilled tutor who is tutoring a student in a subject you know very well.\\\n",
    "The student is struggling to understand a concept. You decide to explain the concept to the student \\\n",
    "in a way that is easy to understand.\"\n",
    "user_prompt = \"\"\"Please explain what this code does and why:\n",
    "user_promptyield from {book.get(\"author\") for book in books if book.get(\"author\")}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64f421f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "def get_answer_llama():\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978e8706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This code snippet appears to be a part of a larger data processing or filtering pipeline, possibly using the Pandas library, given the use of `.get()` and list comprehension syntax.\n",
       "\n",
       "Let's break it down:\n",
       "\n",
       "- `user_promptyield`: This variable is created based on an iterable object (in this case, likely `books`) that produces values from two sources:\n",
       "  - `{book.get(\"author\") for book in books} `: This part uses a dictionary lookup (`book.get(\"author)\")`) and assigns the result to each iteration of the loop as the `.yield` keyword is not used here but if we look at another possible version using `(yield * [book.get('author') for book in books])`, it generates values from this generator expression.\n",
       "- `if book.get(\"author\")`: This part filters out any items in the `books` collection where \"author\" key does not exist.\n",
       "\n",
       "In essence, this code snippet will iterate over the `books` dataset and provide the author names if they are present as keys in the dictionary. \n",
       "\n",
       "For better readability and understanding here is a more readable version:\n",
       "\n",
       "python\n",
       "books_filter = [book.get('author') for book in books if 'author' in book]\n",
       "\n",
       "This will achieve the same result, but it assigns the filtered list directly to `books_filter`, which could be helpful when used in further processing.\n",
       "\n",
       "So, this code snippet seems to aim at filtering out items and extracting only the author information that exists as a key in each dictionary."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_answer_llama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d99ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
